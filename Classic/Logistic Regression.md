# Логистическая регрессия и метрики классификации

## Часть 1: Логистическая регрессия

### Что такое логистическая регрессия?

Это алгоритм машинного обучения, который отвечает на вопрос "Да или нет?" или выбирает один класс из нескольких. Например: "Спам это письмо или нет?", "Купит ли клиент товар?", "Какая категория документа?". То есть модель для задачи классификации.

Модель работает так:

1. Берет информацию о предмете (числовые признаки)
2. Комбинирует их специальным способом
3. Преобразует результат в вероятность от 0 до 1

Ключевой инструмент: сигмоидная функция — S-образная кривая, которая "сжимает" любое число в диапазон от 0 до 1.

### Математика логистической регрессии

#### Сигмоидная функция (логистическая функция)

sˉigma(x)=11+e−xsˉigma(x)=1+e−x1​

Что это значит на практике:

- Если аргумент огромный и положительный → результат близок к 1
- Если аргумент огромный и отрицательный → результат близок к 0
- Если аргумент равен 0 → результат равен 0.5

#### Предсказание модели

y^=σ(β0+∑iβixi)=11+e−(β0+∑iβixi)y^​=σ(β0​+∑i​βi​xi​)=1+e−(β0​+∑i​βi​xi​)1​

На простом языке:

- β0β0​ — смещение (bias), влияет на базовую вероятность
- βiβi​ — коэффициенты для каждого признака xixi​
- Сумма β0+∑iβixiβ0​+∑i​βi​xi​ — это линейная часть
- Сигмоида преобразует линейный результат в вероятность

### Интерпретация коэффициентов

В логистической регрессии коэффициенты βiβi​ отвечают за логарифм отношения шансов (log-odds):

ln⁡(p1−p)=β0+∑iβixiln(1−pp​)=β0​+∑i​βi​xi​

Расшифровка:

- Если βi>0βi​>0 → при увеличении признака xixi​ вероятность положительного класса растет
- Если βi<0βi​<0 → при увеличении признака xixi​ вероятность положительного класса падает
- Величина ∣βi∣∣βi​∣ показывает силу влияния

Пример: Если βage=0.05βage​=0.05, то каждый год жизни увеличивает log-odds на 0.05 (примерно на 5% изменяется odds).

> [!IMPORTANT] Коэффициенты в логистической регрессии не совпадают с коэффициентами в линейной регрессии. Они интерпретируются через изменение log-odds, а не через абсолютное изменение yy. Это часто упускается, когда интерпретируют модели на глаз.

### Подбор параметров (обучение модели)

#### Метод максимального правдоподобия

Параметры логистической регрессии находятся методом максимального правдоподобия (Maximum Likelihood Estimation). Это значит: мы ищем такие коэффициенты, которые максимизируют вероятность того, что наши наблюдаемые метки действительно соответствуют модели.

Эквивалентно мы минимизируем функцию потерь log-loss (кросс-энтропию):

J(θ)=−1m∑i=1m(y(i)log⁡y^(i)+(1−y(i))log⁡(1−y^(i)))J(θ)=−m1​∑i=1m​(y(i)logy^​(i)+(1−y(i))log(1−y^​(i)))

Расшифровка:

- mm — количество примеров в данных
- y(i)y(i) — истинный класс (0 или 1)
- y^(i)y^​(i) — предсказанная вероятность
- Первый член штрафует, если модель предсказала низкую вероятность для класса 1
- Второй член штрафует, если модель предсказала высокую вероятность для класса 0

#### Процесс оптимизации: как происходит обучение

1. Инициализация: случайно выбираем начальные коэффициенты βiβi​
2. Forward pass: для каждого примера вычисляем y^=σ(β0+∑iβixi)y^​=σ(β0​+∑i​βi​xi​)
3. Вычисление потерь: считаем, насколько сильно ошибается модель на этом примере
4. Градиентный спуск: чуть-чуть меняем коэффициенты в направлении уменьшения потерь
5. Повторяем: делаем это много раз, пока потери не перестанут улучшаться

> [!NOTE] Логистическая регрессия — выпуклая задача. У функции потерь ровно один глобальный минимум. Поэтому градиентный спуск всегда найдет оптимальное решение, если взять достаточно низкий learning rate. А вот в нейронных сетях (невыпуклые) это не гарантируется!

### Важные замечания

Когда логистическая регрессия хороша:

- Легко интерпретируется: видно ровно, как каждый признак влияет на класс
- Работает быстро и не требует больших вычислительных ресурсов
- Хорошо для бинарной классификации
- Можно масштабировать на очень большие датасеты

Как расширить на многоклассовую классификацию:

- One-vs-Rest (OvR): для каждого класса обучаем отдельную логистическую регрессию (класс vs. остальные)
- Softmax: обобщение сигмоиды на многоклассовый случай, каждый класс получает свою вероятность

Потенциальные проблемы:

- Чувствительна к коррелированным признакам (если две переменные связаны, коэффициенты становятся нестабильными)
- Плохо работает на несбалансированных данных (когда одного класса намного больше)
- Не решает нелинейные задачи (если классы нельзя разделить линией/плоскостью)

Рекомендации для улучшения:

- Стандартизация признаков: приведите все признаки к одному масштабу (mean=0, std=1)
- Регуляризация: добавьте штраф за большие коэффициенты (L1 или L2), это помогает от переобучения
- Feature engineering: создавайте новые признаки, которые лучше разделяют классы

> [!TIP] L1-регуляризация (Lasso) обнуляет некоторые коэффициенты, делая модель скупой. L2-регуляризация (Ridge) уменьшает все коэффициенты, но не обнуляет. Выбор между ними зависит от того, хотите ли вы отбора признаков (L1) или просто сглаживания (L2).

Логистическая регрессия — это простая, быстрая и интерпретируемая модель, которая отлично работает, когда данные линейно разделимы и когда нужна прозрачность решений. Она служит базисом для понимания более сложных алгоритмов.

## Часть 2: Метрики для оценки качества классификации

### Confusion Matrix (Матрица ошибок)

Матрица показывает, как модель ошибается. Для бинарной классификации это таблица 2×2:

||Предсказано: 0|Предсказано: 1|
|---|---|---|
|Истинно: 0|TN (True Negative)|FP (False Positive)|
|Истинно: 1|FN (False Negative)|TP (True Positive)|

Расшифровка:

- TP (True Positive): модель сказала "1", и это верно
- TN (True Negative): модель сказала "0", и это верно
- FP (False Positive): модель сказала "1", но на самом деле "0" (ложная тревога)
- FN (False Negative): модель сказала "0", но на самом деле "1" (упущена позитивная единица)

Пример: Модель для обнаружения болезни

- TP = 80: правильно определила больных
- TN = 900: правильно определила здоровых
- FP = 50: ложная тревога — сказала "болен", а человек здоров (плохо!)
- FN = 20: пропустила болезнь (очень плохо!)

### Accuracy (Точность) — общий процент правильных ответов

Accuracy=TP+TNTP+TN+FP+FNAccuracy=TP+TN+FP+FNTP+TN​

На простом языке: Какой процент примеров модель классифицировала правильно?

Пример: Из 1000 писем модель правильно отнесла 950 к спаму или нормальным → Accuracy = 95%

> [!WARNING] Accuracy — коварная метрика! Если в ваших данных 99% спама и всего 1% нормальных писем, модель может получить 99% accuracy, просто объявив всё спамом. Поэтому при несбалансированных классах используйте другие метрики!

> [!IMPORTANT] Парадокс accuracy: На несбалансированных данных модель-"лентяйка" (которая просто всегда говорит класс большинства) может получить очень высокую accuracy, будучи совершенно бесполезной. Всегда смотрите на confusion matrix!

### Recall (Полнота, Чувствительность) — ловим ли мы нужные случаи?

Recall=TPTP+FNRecall=TP+FNTP​

На простом языке: Из всех реальных положительных случаев, сколько модель правильно определила?

Формулировка: "Из всех больных людей, кого модель определила как больного?"

Пример: Есть 100 действительно больных людей. Модель определила 80 из них как больных. Recall = 80/100 = 80%

Когда это важно:

- Медицина: упустить болезнь (FN) — ужасно, поэтому нужен высокий Recall
- Система обнаружения чрезвычайных ситуаций: пропустить опасность (FN) критично
- Когда стоимость ошибки второго рода (FN) высокая

### Precision (Точность) — когда мы говорим "да", это действительно "да"?

Precision=TPTP+FPPrecision=TP+FPTP​

На простом языке: Из всех случаев, которые модель отнесла к положительному классу, сколько действительно положительны?

Формулировка: "Когда модель говорит 'болен', как часто это верно?"

Пример: Модель определила 100 людей как больных. На самом деле больны только 85. Precision = 85/100 = 85%

Когда это важно:

- Спам-фильтры: если модель отбросит письмо (отнесет в спам), это не должно быть полезное письмо (FP плохой)
- Реклама: если модель показывает объявление, это должна быть релевантная реклама (не тратим бюджет впустую)
- Когда стоимость ошибки первого рода (FP) высокая

### F1-Метрика — золотая середина

F1=2⋅Precision⋅RecallPrecision+RecallF1​=2⋅Precision+RecallPrecision⋅Recall​

На простом языке: Это гармоническое среднее Precision и Recall. Штрафует нас, если одна из метрик очень низкая.

Характеристика:

- Если Precision = 100%, но Recall = 10% → F1 ≈ 18% (низко!)
- Если Precision = 90%, Recall = 90% → F1 ≈ 90% (хорошо!)

Когда использовать: Когда нужен баланс между "не упустить важные случаи" (Recall) и "не создавать ложные тревоги" (Precision).

> [!TIP] F1 — это "выравниватель" для несбалансированных данных. F1 не позволяет модели "схитрить", получив высокую метрику за счет класса большинства. Она гармонизирует ошибки двух типов.

### Дополнительные метрики

#### Specificity (Специфичность) — ловим ли мы отрицательные?

Specificity=TNTN+FPSpecificity=TN+FPTN​

На простом языке: Из всех реальных отрицательных случаев, сколько модель правильно определила как отрицательные?

Зеркало Recall, но для класса "0" вместо "1".

#### Negative Predictive Value (NPV) — когда говорим "нет"?

NPV=TNTN+FNNPV=TN+FNTN​

На простом языке: Когда модель говорит "не болен", как часто это правда?

#### Positive Predictive Value (PPV)

Это просто другое имя для Precision.

### ROC-кривая и AUC

#### Что такое ROC-кривая?

ROC расшифровывается как Receiver Operator Characteristic. Это график зависимости:

- По оси Y: True Positive Rate (TPR, она же Recall) — какой процент положительных мы поймали
- По оси X: False Positive Rate (FPR) — какой процент отрицательных мы ошибочно отнесли к положительным

TPR=TPTP+FN(Recall)TPR=TP+FNTP​(Recall)

FPR=FPFP+TN(1 - Specificity)FPR=FP+TNFP​(1 - Specificity)

#### Как строится ROC-кривая?

Обычно логистическая регрессия предсказывает вероятность класса (число от 0 до 1). Мы берем разные пороги (threshold):

- При пороге 0.5: вероятность ≥ 0.5 → класс 1, иначе класс 0
- При пороге 0.3: вероятность ≥ 0.3 → класс 1, иначе класс 0
- При пороге 0.7: вероятность ≥ 0.7 → класс 1, иначе класс 0

Для каждого порога вычисляем TPR и FPR, рисуем точку. Получается кривая.

#### AUC (Area Under Curve) — площадь под кривой

AUC∈[0,1]AUC∈[0,1]

- AUC = 1.0: идеальный классификатор (кривая идет в верхний левый угол)
- AUC = 0.5: модель классифицирует случайно (диагональная линия)
- AUC < 0.5: модель хуже случайности (очень плохо!)
- AUC ≈ 0.7–0.8: приличный классификатор
- AUC ≈ 0.8–0.9: хороший классификатор
- AUC > 0.9: отличный классификатор

Преимущество AUC: Это пороговонезависимая метрика — не зависит от выбора конкретного порога решения.

> [!NOTE] ROC/AUC особенно полезна, когда стоимость ошибок первого и второго рода разная. График показывает, как меняется баланс при движении порога. Например, в медицине можно выбрать порог так, чтобы Recall был выше (не пропускаем болезни), пожертвовав Precision (допускаем ложные тревоги).

### Практические рекомендации по выбору метрик

|Сценарий|Главная метрика|Дополнительные|
|---|---|---|
|Медицина (диагностика)|Recall|Specificity, ROC-AUC|
|Спам-фильтры|Precision|Recall|
|Сбалансированные данные|Accuracy, F1|Precision, Recall|
|Несбалансированные данные|F1, ROC-AUC|Precision, Recall, Confusion Matrix|
|Информационный поиск|Recall|Precision|
|Ранжирование|nDCG, MAP|—|

Общий алгоритм:

1. Начните с confusion matrix — видите ли вы, где модель ошибается?
2. Определите цель: что хуже — ложные тревоги (FP) или упущенные случаи (FN)?
3. Выберите метрику: если важен Recall → ориентируйтесь на Recall; если Precision → на Precision
4. Проверьте ROC-AUC: для общей оценки качества разделения классов
5. Подстройте порог: если нужно, можно смещать баланс Precision-Recall

## Взаимосвязь: от модели к метрикам

Данные → Логистическая регрессия → Вероятности → Пороговое решение → Предсказания → Confusion Matrix → Метрики

1. Данные: признаки xixi​ и истинные метки yy
2. Логистическая регрессия: обучается минимизировать log-loss, получает коэффициенты βiβi​
3. Вероятности: модель предсказывает y^∈[0,1]y^​∈[0,1]
4. Пороговое решение: выбираем порог (обычно 0.5): если y^≥0.5y^​≥0.5 → класс 1, иначе 0
5. Предсказания: получаем бинарные предсказания
6. Confusion Matrix: сравниваем с истинными метками
7. Метрики: вычисляем Accuracy, Precision, Recall, F1, ROC-AUC

## Практические советы

Делайте так:

- Всегда смотрите на confusion matrix первым делом
- Для несбалансированных данных используйте F1, Recall/Precision, не Accuracy
- При выборе порога используйте ROC-кривую, чтобы видеть компромиссы
- Стандартизируйте признаки перед обучением логистической регрессии
- Используйте кросс-валидацию, чтобы метрики были стабильными

Не делайте так:

- Не верьте одной метрике, смотрите на несколько
- Не берите Accuracy как единственную метрику на несбалансированных данных
- Не забывайте про порог — изменение порога меняет баланс ошибок
- Не используйте слишком высокий learning rate при обучении (потеряете оптимум)

## Справка: когда что использовать на практике

```python
if данные_сбалансированы:
    метрика = accuracy
else:
    if важнее_не_пропустить_положительные:
        метрика = recall
    elif важнее_не_создавать_ложные_тревоги:
        метрика = precision
    else:
        метрика = f1

метрика = roc_auc
```

Логистическая регрессия и метрики классификации — это не просто формулы. Это язык, на котором вы общаетесь с данными и объясняете другим, почему ваша модель хороша или плоха. Учитесь их понимать интуитивно, а не просто запоминайте формулы.