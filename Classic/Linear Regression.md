# Линейная регрессия в машинном обучении

## Supervised Learning: Обучение с учителем

### Основная идея

Обучение с учителем — это подход в машинном обучении, где модель учится на примерах с уже известными правильными ответами. Представьте, что вы показываете ребёнку фотографии животных и говорите: "Это кошка, это собака". Так же и модель учится на размеченных данных.

**Ключевые компоненты:**
- Признаки (features) — характеристики объектов, обозначаются как X
- Целевая переменная (target) — то, что мы хотим предсказать, обозначается как y
- Обучающая выборка — данные, на которых модель учится
- Тестовая выборка — данные для проверки качества модели

**О разделении данных:** Разделение на обучающую и тестовую выборки критически важно для оценки обобщающей способности модели. Типичное соотношение: 70-80% на обучение, 20-30% на тест. Для более надёжной оценки используют кросс-валидацию (cross-validation), где данные разбиваются на k частей, и модель обучается k раз, каждый раз используя разные части для обучения и теста. Это помогает избежать случайного удачного или неудачного разделения данных.

> [!IMPORTANT]
> **Без утечек (no leakage): всё, что «учится на данных» — только внутри `Pipeline` и только на train.**  
> Скейлинг, импутация пропусков, отбор признаков и любые трансформации должны обучаться **только на обучающей части** (в каждом фолде при кросс-валидации). Это предотвращает «подглядывание» в тест и завышенные метрики.
>
> <details>
>   <summary><strong>Что именно относится к «учится на данных»</strong></summary>
>   — Импутация (среднее/медиана/мода, KNN, MICE)  
>   — Масштабирование/нормализация (Standard/MinMax/Robust)  
>   — Кодирование категорий (One-Hot, Target/Mean, CE)  
>   — Отбор/генерация признаков (PCA, SVD, полиномиальные фичи)  
>   — Подбор порогов/правил, «умные» бины и т.п.
> </details>

---

> [!TIP]
> **Распределение классов на тренировочном наборе должно сохранять распределение тестового набора или продакшн-данных.**
> <details>
>   <summary><strong>Что это значит?</strong></summary>
>   Если распределение на production было 1 к 5 (один положительный пример > на пять отрицательных), то в тренировочном наборе хотелось бы, чтобы оно осталось таким же. Это делается, чтобы избежать data-shifting'a и перекоса весов, ведь функция распределения вносит немалый вклад в окончательный вид модели.
> </details>


### Этапы работы с данными

### 1. Подготовка данных
Собираем и сохраняем наблюдения вместе с правильными ответами. Например, цены квартир (ответ) и их характеристики: площадь, количество комнат, район (признаки).

### 2. Очистка данных
Обрабатываем пропуски, исправляем ошибки, приводим данные к единому формату. Это критически важный этап — "мусор на входе = мусор на выходе".

**Работа с пропусками:** Существует несколько стратегий обработки пропущенных значений:
- Удаление строк с пропусками (если их мало, обычно менее 5%)
- Заполнение средним значением для числовых признаков
- Заполнение медианой (устойчивее к выбросам)
- Заполнение модой для категориальных признаков
- KNN-импутация (заполнение на основе похожих объектов)
- Предсказание пропущенных значений с помощью других признаков

Выбор метода зависит от природы данных и доли пропусков. Важно не потерять информацию, но и не исказить распределение.

> [!WARNING]
> **Feature leakage-ловушки:** избегай признаков, содержащих информацию из будущего или из целевой переменной.  
> Пример: когда предсказываешь «цену без НДС», нельзя использовать «итоговую сумму с НДС» или любые агрегаты, посчитанные с участием цели.  
> Для временных данных — **замораживай** вычисления по времени: агрегаты, лаги и скользящие статистики должны использовать только прошлое, а сплит делать по времени (train < test).


### 3. Исследовательский анализ
Изучаем распределения переменных, ищем связи между признаками, визуализируем данные. Здесь помогают графики, корреляционные матрицы, статистические тесты.

### 4. Обучение модели
Выбираем алгоритм, настраиваем параметры, обучаем модель на тренировочных данных, проверяем на тестовых.

#### Бейзлайн (baseline) — с чего начать
> [!NOTE]
> **Всегда сравнивайся с наивной моделью** — это ловит переобучение и даёт ориентир.
>
> Мини-набор бенчмарков:
> - **Среднее/медиана** по train (константный предиктор)  
> - **Простая линейная регрессия** с минимальной предобработкой  
> - (для рядов) **наивный прогноз**: последнее значение или сезонный наивный
>
> Если модель не обгоняет бейзлайны — проблема в данных/утечках/валидации.

---
### 5. Тюнинг гиперпараметров: лог-шкала
> [!TIP]
> Параметры-регуляризации и скорости обучения подбирай на **логарифмической сетке**.  
> Примеры:
> - Ridge/Lasso/ElasticNet: `alpha ∈ {1e−4, 1e−3, ..., 1e2}`  
> - Градиентные бустинги/нейросети: `learning_rate ∈ {1e−3, 3e−3, 1e−2, 3e−2, 1e−1}`  
> - Древовидные регуляризации (λ, γ и пр.): также лог-сетка
>
> Лог-шкала покрывает порядки величин и чаще находит «правильный диапазон», чем равномерная линейная сетка.


---

## Линейная регрессия: От простого к сложному

### Суть метода

Линейная регрессия — это попытка найти прямую линию (или плоскость в многомерном пространстве), которая наилучшим образом описывает зависимость между признаками и целевой переменной.

**Простая линейная регрессия (один признак):**

$\hat{y}$ = $b_0$ + $b_1 x$

где:
- $\hat{y}$ (читается "игрек с крышечкой") — предсказанное значение
- $b_0$ — свободный член (intercept), точка пересечения с осью Y
- $b_1$ — коэффициент наклона (slope), показывает, как изменится $y$ при изменении $x$ на единицу
- $x$ — значение признака

**Множественная линейная регрессия (несколько признаков):**

$\hat{y}$ = $\beta_0$ + $\beta_1 x_1$ + $\beta_2 x_2$ + ... + $\beta_n x_n$

### Как модель находит коэффициенты?

Модель подбирает такие значения $b_0, b_1, \dots, b_n$, чтобы минимизировать ошибки предсказаний. Чаще всего используется метод наименьших квадратов ($\text{OLS}$).

**О методе наименьших квадратов:** Это математический метод, который находит коэффициенты, минимизирующие сумму квадратов ошибок. Имеет аналитическое решение через матричные операции: $beta = (X^T X)^{-1} X^T y$. Метод требует выполнения нескольких важных предположений:
- Линейность связи между признаками и целевой переменной
- Независимость наблюдений друг от друга
- Гомоскедастичность (постоянная дисперсия ошибок по всем значениям)
- Нормальность распределения ошибок (для статистических выводов)

Нарушение этих предположений может привести к неточным предсказаниям и неверным статистическим выводам.

---

## Метрики качества: Как оценить модель

### MSE (Mean Squared Error) — Среднеквадратичная ошибка

$$
MSE = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2
$$

**Что показывает:** среднее значение квадратов разностей между реальными и предсказанными значениями.

**Особенности:**
- Сильно штрафует за большие ошибки (квадрат усиливает влияние)
- Чувствительна к выбросам
- Используется как функция потерь при обучении модели

**Пример:** если модель ошиблась на 10 рублей, штраф = 100; если на 2 рубля, штраф = 4.

**Функция потерь:** MSE часто используется как функция потерь (loss function) — метрика, которую модель минимизирует в процессе обучения. MSE удобна, потому что она дифференцируема (можно применить градиентный спуск для оптимизации) и автоматически штрафует за большие ошибки сильнее, чем за маленькие. Это желаемое свойство во многих задачах, где критичны именно крупные промахи.

### RMSE (Root Mean Squared Error) — Корень из MSE

$$
RMSE = \sqrt{MSE}
$$

**Преимущество:** измеряется в тех же единицах, что и целевая переменная. Если предсказываем цены в рублях, RMSE тоже будет в рублях — это удобно для интерпретации.

### MAE (Mean Absolute Error) — Средняя абсолютная ошибка

$$
MAE = \frac{1}{n} \sum_{i=1}^n |y_i - \hat{y}_i|
$$

**Что показывает:** средняя величина ошибки без учёта направления.

**Особенности:**
- Более устойчива к выбросам, чем MSE/RMSE
- Все ошибки влияют одинаково (нет квадрата)
- Лучше отражает "типичную" ошибку модели

**Когда использовать:** если в данных есть выбросы, и вы не хотите, чтобы модель слишком сильно на них реагировала.

### R² (R-squared) — Коэффициент детерминации

$$
R^2 = 1 - \frac{\sum (y_i - \hat{y}_i)^2}{\sum (y_i - \bar{y})^2}
$$

где $\bar{y}$ — среднее значение целевой переменной.

**Интерпретация:**
- \(R^2 = 1\) — модель идеально предсказывает данные
- \(R^2 = 0\) — модель не лучше простого среднего значения
- \(R^2 < 0\) — модель хуже среднего (плохой знак!)
- \(R^2 = 0.85\) — модель объясняет 85% вариации данных

**О вариации:** Вариация (дисперсия) — это мера разброса данных. \(R^2\) показывает, какую долю от общей вариации целевой переменной объясняет модель. Числитель в формуле — это сумма квадратов остатков (необъяснённая модель дисперсия), знаменатель — общая дисперсия целевой переменной. Оставшаяся часть (1 - \(R^2\)) — это необъяснённая вариация, которая может быть шумом, случайностью или влиянием неучтённых факторов.

**Важное ограничение:** высокий \(R^2\) не всегда означает хорошую модель. Он может расти при добавлении любых признаков, даже бесполезных или случайных. Поэтому \(R^2\) нужно использовать вместе с другими метриками и здравым смыслом.

### Adjusted R² — Скорректированный R²

$$
\text{Adjusted}\ R^2 = 1 - (1 - R^2) \frac{n-1}{n-p-1}
$$

где:
- \(n\) — количество наблюдений
- \(p\) — количество признаков

**Зачем нужен:** штрафует модель за избыточное количество признаков. Помогает сравнивать модели с разным числом переменных и бороться с переобучением.

**Проблема переобучения:** Переобучение (overfitting) возникает, когда модель слишком хорошо "запоминает" обучающие данные, включая шум и случайные флуктуации, и плохо работает на новых данных. Модель становится слишком сложной для имеющихся данных. Adjusted \(R^2\) помогает бороться с этим, штрафуя за добавление признаков, которые не улучшают качество модели существенно. Другие методы борьбы с переобучением: регуляризация (Ridge, Lasso), валидация на отложенной выборке, кросс-валидация, feature selection (отбор признаков), увеличение объёма данных.

---

## Практические рекомендации по выбору метрик

### Используйте MSE/RMSE, если:
- Большие ошибки критичны (финансы, медицина)
- Нужна гладкая функция потерь для оптимизации
- В данных нет сильных выбросов

### Используйте MAE, если:
- Все ошибки одинаково важны
- Данные содержат выбросы
- Нужна интуитивная интерпретация (средняя ошибка в рублях/метрах/штуках)

### Используйте R², если:
- Нужно быстро оценить качество модели
- Хотите понять долю объяснённой дисперсии
- Сравниваете модели с одинаковым числом признаков

### Используйте Adjusted R², если:
- Сравниваете модели разной сложности
- Выбираете между моделями с разным количеством признаков
- Хотите избежать переобучения

**Общий совет:** используйте несколько метрик одновременно для комплексной оценки модели. Например, RMSE для оценки абсолютной величины ошибки и \(R^2\) для понимания качества объяснения данных.


Как и обещал: [ноутбук для изучения](Notebooks/LinearRegression_Tutorial.ipynb)