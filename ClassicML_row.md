  

# Полиномиальная регрессия, зависимость ошибок и баланс подгонки

## Когда нужна полиномиальная регрессия?

- Если между признаками и целевой переменной наблюдается **нелинейная связь** (пример: $y = \log(x)$ или $y = (\log(x))^2$).
- Если есть **зависимость между признаками** (например, один признак влияет на другой, синергия).

**Совет:** Чем выше степень полинома — тем лучше модель описывает сложные зависимости, но возрастает риск переобучения.

---

## Баланс смещения и разброса (Bias-Variance Trade-off)

- **Смещение (bias):** насколько усреднённое предсказание модели отличается от реальных данных (простая, "грубая" модель).
- **Дисперсия (variance):** насколько сильно предсказания модели меняются при обучении на разных обучающих выборках (сложная, "чувствительная" модель).

---

## Переобучение (overfitting) и недообучение (underfitting)

### a) Переобучение (overfitting)
- Модель слишком точно повторяет шум в обучающих данных.
- Высокая дисперсия, низкое смещение.
- Отличные значения на обучающей выборке, плохие — на тестовой/реальных данных.
- Пример: высокая степень полинома, сильно извилистая линия регрессии.

### b) Недообучение (underfitting)
- Модель не способна уловить закономерности даже в обучающих данных.
- Высокое смещение, низкая дисперсия.
- Пример: слишком простая модель по сравнению с реальными закономерностями.

---

## Как выбрать оптимальную сложность модели?

- В идеальном случае **ошибка уменьшается с ростом степени полинома** до определённого момента, после чего начинает расти на тестовой выборке — признак переобучения.

График:
- Ошибка на train set всегда уменьшается с усложнением модели.
- Ошибка на test set сначала падает, затем растёт (стоит выбрать область минимума тестовой ошибки).

---

## Итоги: подход к построению качественной регрессии

- Выявлять линейные и нелинейные зависимости.
- Следить за мультиколлинеарностью (влияние признаков друг на друга).
- Балансировать между смещением и разбросом, чтобы модель была интерпретируема и устойчива на новых данных.
- Использовать регуляризацию для борьбы с переобучением.

> Грамотный выбор степени полинома и сложности регрессионной модели основывается на анализе ошибок, визуализации и сравнении метрик на обучающей и тестовой выборках.

# Регуляризация в линейной регрессии

## Зачем нужна регуляризация?

- **Минимизация сложности модели** — защита от переобучения (overfitting).
- **Штраф за “лишние” параметры** — модель не подбирает слишком сложные зависимости из-за шума.
- **Уменьшение разброса (variance)** при сохранении качества объяснения.

---

## Суть регуляризации

- В оптимизационную функцию добавляется штраф (penalty) за размер коэффициентов.
- Задача: найти баланс между объяснённой дисперсией и простотой модели.

---

## Основные типы регуляризации

1. **L2-регрессия (Ridge regression):**
   $$
   Error = \sum_{i=1}^n (y_i - \hat{y}_i)^2 + \lambda \sum_{j=1}^p \beta_j^2
   $$
   Штрафует большие коэффициенты $\beta_j$, размывает их значения.

2. **L1-регрессия (LASSO):**
   $$
   Error = \sum_{i=1}^n (y_i - \hat{y}_i)^2 + \lambda \sum_{j=1}^p |\beta_j|
   $$
   Стремится занулять незначимые коэффициенты — выполняет отбор признаков.

3. **Elastic Net** (гибрид L1 и L2):
   $$
   Error = \sum_{i=1}^n (y_i - \hat{y}_i)^2 + \lambda_1 \sum_{j=1}^p |\beta_j| + \lambda_2 \sum_{j=1}^p \beta_j^2
   $$
   Управляет долей L1/L2 через параметр $\alpha$ ($\alpha=1$ — LASSO, $\alpha=0$ — Ridge).

---

## Иллюстрация влияния штрафов

- **Ridge:** все веса “сглаживаются”, коэффициенты мало зануляются.
- **LASSO:** ярко выраженная склонность к обнулению коэффициентов, что важно при отборе признаков.
- **Elastic Net:** сочетает преимущества обеих техник.

---

## Практическая реализация

Для работы с регуляризацией обычно:

1. Масштабируют (нормируют) признаки (StandardScaler);
2. Выбирают способ расширения признаков (полиномиальные признаки);
3. Задают параметры регуляризации (например, через кросс-валидацию ищут $\lambda$ и $\alpha$).

Фрагмент кода (python, sklearn):

```
from sklearn.preprocessing import PolynomialFeatures, StandardScaler  
poly = PolynomialFeatures(degree=3)  
X_poly = poly.fit_transform(X)

scaler = StandardScaler()  
X_poly_scaled = scaler.fit_transform(X_poly)
```

---

## В каких задачах что использовать?

- **Ridge** — когда признаки скоррелированы, задача — снизить разброс и сохранить все признаки.
- **LASSO** — если важен автоматический отбор признаков (сделать модель sparse).
- **Elastic Net** — если есть несколько важных и коррелированных признаков и требуется гибкость контроль sparsity vs. smoothness.

---

> Регуляризация — мощный инструмент для повышения обобщающей способности модели, борьбы с переобучением и оптимизации структуры регрессии при большом числе признаков.

# Масштабирование признаков

## Зачем нужно масштабирование?

- Масштабирование признаков ускоряет и стабилизирует сходимость итерационных алгоритмов (особенно градиентный спуск) и важно для многих моделей, чувствительных к масштабу признаков (Ridge, LASSO, SVM, kNN, PCA и др.).
- Если признаки имеют разный масштаб, алгоритм будет уделять больше внимания признакам с большими значениями — это приводит к искажению построения весов и выбору неинформативных признаков.

---

## Преимущества масштабирования

- Уменьшает разброс значений и обеспечивает единый "вес" для признаков.
- Повышает сходимость обучения.
- Позволяет корректно рассчитывать коэффициенты.
- Улучшает работу моделей, которые основаны на расстояниях.

---

## Основные способы масштабирования

### 1. Стандартизация (Standardization)

- Приводит данные к виду с $\mu=0$ (среднее) и $\sigma=1$ (стандартное отклонение):
  $$
  X_{\text{scaled}} = \frac{X - \mu}{\sigma}
  $$
- Применяется при наличии выбросов, хорошо работает с большинством алгоритмов машинного обучения.

### 2. Нормализация (Min-Max scaling)

- Приводит значения признаков к диапазону $[0, 1]$:
  $$
  X_{\text{scaled}} = \frac{X - X_{\min}}{X_{\max} - X_{\min}}
  $$
- Особенно удобна для изображений и нейросетей, где входные значения стандартизируют в единый диапазон.

---

## Как правильно масштабировать данные?

- Всегда производить масштабирование **только на обучающей выборке!**
    - Разбиваем данные на train/test;
    - Фитим (fit) трансформер по train;
    - Применяем transform к train и test.
- Это предотвращает “утечку” информации из тестовой выборки в обучение.

---

> Грамотное масштабирование — обязательный этап современного ML-процесса: оно позволяет корректно сравнивать признаки, улучшает качество и устойчивость работы большинства алгоритмов.

# Подготовка признаков (Feature Engineering) и очистка данных

## Категориальные признаки — основные подходы

**Feature engineering** (конструирование признаков) — процесс извлечения, комбинирования и преобразования исходных данных для формирования новых, полезных признаков.

### Три главные задачи:

- **Извлечение информации:** выделяем смысловые части из сложных данных (например, из 1990-08-12  9:16:00 можно получить год, месяц, день недели и т.д.).
- **Комбинирование признаков:** формируем новые признаки из нескольких (например, разница между входом и выходом, или признак "уровень энергии").
- **Преобразование признаков:** кодирование категориальных данных:
  - **Integer encoding:** каждому уникальному значению категории назначается свой номер.
  - **One-hot encoding:** для каждой категории создаётся отдельный бинарный столбец ("столбцы-единицы").

---

## Работа с выбросами (Outliers)

- **Выбросы** — точки, которые существенно отличаются от остальных данных.
- Как правило, выбросы либо удаляют, либо анализируют отдельно.

### Как вычислить выбросы?

- **Четвертевой интервал (IQR):**  
  Расходящиеся точки за пределами $[Q1 - 1.5 \cdot IQR, Q3 + 1.5 \cdot IQR]$ считаются выбросами.
    - $Q1$ — 25% квантиль, $Q3$ — 75% квантиль.
    - Используются функции Pandas: `series.quantile()`, `series.describe()`, `sns.boxplot()`.

- **Визуализация:**  
  Построение boxplot, scatter plot, сравнение распределения с медианой/средним значением.

- **Стратегии обработки:**
  - Удаление точки полностью (если данные заведомо неверны).
  - Заменить выброс на значение медианы или квартиля, если это допустимо задачей.
  - Проверка: выброс не должен превышать нескольких сигм (стандартных отклонений) для большинства признаков.

---

## Отсутствующие данные (Missing data)

- **Обработка пропусков:**
  - Выбросить строки/объекты с очень небольшим (<1%) или очень большим (>90%) числом пропусков.
  - Заменить пропущенные значения на:
    - Нули
    - Среднее/медиану/моду по столбцу
    - Специальное значение (например, -9999)
    - Продвинутые методы (KNN, MICE, модели предсказания)

---

> Качественно подготовленные признаки и обработанные данные — основа для построения эффективных и устойчивых моделей машинного обучения. Feature engineering делает ваш основной алгоритм гораздо мощнее.

# Кросс-валидация и разбиение данных в машинном обучении

## Зачем нужна кросс-валидация?

- Кросс-валидация — совокупность методов для более надёжной проверки качества модели по сравнению с простым разбиением train/test. Она помогает избежать переобучения и получить устойчивую оценку метрик.
- Особенно полезна, когда мало данных или есть риск, что случайный сплит даст неправильную оценку качества.

---

## Основные подходы к разбиению данных

### 1. Train/Test Split (обучающая и тестовая выборки)

- Данные делятся на обучающую (train) и тестовую (test) части.
- Схема работы:
    - Очищаем и масштабируем признаки (отдельно по train/test).
    - Обучаем модель на train.
    - Оцениваем качество на test.
    - (Повторяем с подгонкой гиперпараметров.)

### 2. Train/Validation/Test Split

- Используется дополнительная валидационная выборка для подбора гиперпараметров и борьбы с переобучением:
    - Train — обучение модели.
    - Validation — настройка/тюнинг гиперпараметров.
    - Test — окончательная проверка качества модели, использовать только для финальной оценки!

---

## Кросс-валидация (Cross-validation)

- Данные разбиваются на K фолдов (обычно K=5 или 10).
- На каждом шаге один фолд используется как validation, остальные — как train.
- Итоговое качество модели — усреднение метрик по всем фолдам. Так мы получаем устойчивую оценку даже при сильной изменчивости в выборках.

### Пример: cross-val-score и cross_validate в sklearn

- `cross_val_score(model, X, y, cv=5)` — быстрая оценка средней метрики.
- `cross_validate(model, X, y, scoring=..., cv=5)` — расширенная функция: можно смотреть сразу несколько метрик, вычислять время обучения и предсказания.

---

## Grid Search и Random Search для подбора гиперпараметров

- **Grid Search (GridSearchCV)** — полный перебор всех возможных комбинаций параметров из заданной сетки. Очень тщательный, но затратный по времени.
- **Random Search (RandomizedSearchCV)** — случайно отбирает фиксированное число комбинаций. Часто быстрее grid search, позволяет оценить самые вероятные удачные гиперпараметры за меньшее время.

---

> Правильное разбиение на train/test/validation, а также применение кросс-валидации и тюнинг гиперпараметров — основа для объективной оценки и оптимизации моделей машинного обучения.


# Логистическая регрессия: основы, математика, подбор параметров

## Что такое логистическая регрессия?

- Это базовый алгоритм классификации для предсказания категориальной (дискретной) переменной.
- Основан на применении сигмоидной функции для перевода линейной комбинации признаков в вероятность класса.

---

## Формула логистической регрессии

- Сигмоида (логистическая функция):
  $$
  \sigma(x) = \frac{1}{1 + e^{-x}}
  $$
- Прогноз модели:
  $$
  \hat{y} = \sigma(\beta_0 + \sum_{i}\beta_i x_i) = \frac{1}{1 + e^{-(\beta_0 + \sum_{i}\beta_i x_i)}}
  $$

---

## Интерпретация коэффициентов

- В логистической регрессии коэффициенты $\beta_i$ отвечают за изменение логарифма отношения шансов (log odds).
  $$
  \ln\left(\frac{p}{1-p}\right) = \beta_0 + \sum_{i} \beta_i x_i
  $$
- Положительное $\beta_i$ — увеличение вероятности класса $1$ с ростом $x_i$.
- Отрицательное $\beta_i$ — снижение вероятности с ростом $x_i$.

---

## Подбор параметров (обучение)

- Параметры логистической регрессии подбираются методом максимального правдоподобия (maximum likelihood).
- Максимизируется вероятность наблюдаемых меток, или что то же самое, минимизируется log-loss (кросс-энтропийная функция потерь):

  $$
  J(\theta) = -\frac{1}{m} \sum_{i=1}^m \big( y^{(i)} \log \hat{y}^{(i)} + (1 - y^{(i)}) \log(1 - \hat{y}^{(i)}) \big)
  $$
- Можно записать через log-odds и вероятности.

---

## Оптимизация: как идет обучение

1. Преобразуем $\hat{y}$ в odds, затем обратно в вероятности через $\sigma(x)$.
2. Каждый пример получает свой вклад в функцию правдоподобия.
3. Логарифмируем, чтобы получить log-likelihood.
4. Используем градиентный спуск для минимизации log-loss.

---

## Важные замечания

- Логистическая регрессия хорошо интерпретируется (можно явно увидеть вклад каждого признака).
- Работает как для бинарной, так и для многоклассовой классификации (One-vs-Rest, Softmax).
- Чувствительна к коррелированным и несбалансированным признакам — рекомендуется стандартизация и регуляризация.

---

> Логистическая регрессия — это не только мощный и простой базис для большинства задач классификации, но и инструмент глубокой интерпретации данных с понятной математикой и прозрачностью работы.

# Метрики для оценки качества классификации

## Confusion matrix (матрица ошибок)

- Показывает распределение предсказаний модели по классам:  
  - **True Positive (TP):** верно предсказан положительный класс
  - **True Negative (TN):** верно предсказан отрицательный класс
  - **False Positive (FP):** ошибочно предсказан положительный (ложноположительный)
  - **False Negative (FN):** ошибочно предсказан отрицательный (ложноотрицательный)

---

## Accuracy (точность)

$$
Accuracy = \frac{TP + TN}{Total}
$$

- Доля правильных ответов. *Важное замечание:* accuracy не всегда уместна при несбалансированных классах, потому что модель может получать высокое значение, пренебрегая редким, но важным классом.

---

## Recall (полнота, чувствительность)

- Показывает, как часто модель правильно определяет истинные положительные случаи среди всех реальных положительных:

$$
Recall = \frac{TP}{TP + FN}
$$

---

## Precision (точность)

- Показывает, как часто модель была права при предсказании положительного класса:

$$
Precision = \frac{TP}{TP + FP}
$$

---

## F1-метрика

- Гармоническое среднее precision и recall, является балансом между этими метриками:
$$
F_1 = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall}
$$

---

## Дополнительные метрики

- Специфичность (Specificity): $\frac{TN}{TN + FP}$ — доля верно предсказанных отрицательных классов.
- Negative predictive value (NPV) — вероятность, что предсказанный отрицательный действительно отрицательный.
- Positive predictive value (PPV), он же Precision.

---

## ROC-кривая (Receiver Operator Characteristic)

- График зависимости полноты (TPR, чувствительности) от доли ложных срабатываний (FPR).
- Строится путём перебора возможных порогов для вероятности класса.
- Чем больше площадь под ROC-кривой (**AUC**), тем лучше в среднем модель разделяет классы:
  - AUC = 1 — идеальный классификатор
  - AUC = 0.5 — случайный выбор

---

## Практические рекомендации

- Много метрик — подходит для разных задач: медицина (лучше повышенная Recall), финансы и спам-фильтры (важен Precision).
- Всегда нужен анализ confusion matrix: одна метрка может не заметить перекосы в данных.
- В задачах со сложной ценой ошибки (ошибка первой/второй рода) анализируют ROC и подбирают рабочий порог.

---

> Метрики качества классификации позволяют гибко оценивать работу моделей и подбирать критерии, которые максимально соответствуют задаче и бизнес-целям.

# Метод k-ближайших соседей (k-NN)

## Принцип работы

- **Идея:** чтобы предсказать класс объекта, найдём $k$ ближайших к нему точек из обучающей выборки и выберем наиболее частый среди их классов.
- Основан на гипотезе **локального сходства**: схожие объекты имеют схожие метки (в задачах классификации) или значения (в задачах регрессии).

---

## Алгоритм k-NN

1. **Выбираем число ближайших соседей $k$** (обычно нечётное, чтобы избежать ничьих).

2. **Вычисляем расстояние** от тестового объекта до всех объектов обучающей выборки.

3. **Находим $k$ ближайших соседей** (с наименьшими расстояниями).

4. **В задаче классификации:** выбираем класс, который чаще всего встречается среди $k$ соседей.  
   **В задаче регрессии:** берём среднее (или взвешенное среднее) значение целевой переменной соседей.

---

## Варианты расчёта расстояний

- **Евклидово расстояние** — наиболее распространённое:
  $$
  d(x_1, x_2) = \sqrt{\sum_{i=1}^n (x_{1i} - x_{2i})^2}
  $$

- **Манхэттенское расстояние:**
  $$
  d(x_1, x_2) = \sum_{i=1}^n |x_{1i} - x_{2i}|
  $$

- **Расстояние Чебышёва, косинусная близость** и другие метрики.

---

## Выбор оптимального $k$

- **Elbow method** — строим график качества модели от $k$ и ищем "локоть" (точку перегиба).
- **Кросс-валидация с Grid Search** для поиска оптимального значения $k$.

### Рекомендации:

- Малые $k$ (1-3) — высокая чувствительность к шуму, переобучение.
- Большие $k$ — сглаживание, но потеря локальной специфики.
- Правило большого пальца: $k = \sqrt{N}$, где $N$ — размер обучающей выборки.

---

## Алгоритм k-NN: варианты реализации

### Метрики расстояния:
- **Расстояние Минковского**
- **Евклидова метрика**
- **Расстояние хэммингов и мерцавия (Manhattan)**
- **Расстояние Чебышёва**

### Важные особенности:
- k-NN — **"ленивый" алгоритм**: не строит явную модель, вычисления происходят только при предсказании.
- Требователен к масштабированию признаков (рекомендуется стандартизация или нормализация).
- Вычислительная сложность растёт с размером обучающей выборки.

---

> k-NN — простой и интуитивный алгоритм, который отлично работает на задачах с локальными зависимостями, но требует грамотного выбора $k$ и метрики расстояния для достижения оптимального качества.

# Метод опорных векторов (SVM)

## Интуитивность SVM

- **В одномерном случае** — это точка, разделяющая два класса.
- **В двумерном случае** — линия, отделяющая классы друг от друга.
- **В трёхмерном и выше** — гиперплоскость, разделяющая пространство.

---

## Ключевая идея: максимизация зазора (margin)

- **Основной метод SVM** — найти такой разделитель, чтобы максимизировать расстояние (margin) между опорными векторами от двух классов.
- Когда новые точки оказываются по ту или иную сторону гиперплоскости, им назначается соответствующий класс.

**Правило выбора разделителя:**  
Лучше выбрать такой разделитель, чтобы максимизировать зазоры (margins) между классами.

---

## Hard margin vs Soft margin

### Hard Margin
- Если данные не разделимы идеально, то алгоритм не может построить разделитель (bias), что приводит к излишней чувствительности к выбросам и использовать нельзя.

### Soft Margin
- Алгоритм позволяет некоторым точкам из классификационной выборки попадать в пространство между классами или даже на неправильную сторону.
- Добавляется штраф за нарушение зазора.

---

## SVM: математическое описание

- Разделяющая гиперплоскость задается уравнением:
  $$
  \mathbf{w} \cdot \mathbf{x} + b = 0
  $$

- **При условии $\frac{1}{||\mathbf{w}||^2} \beta_i^2 = 1$** (нормировка), задача классификации:
  $$
  y_i(\mathbf{w} \cdot \mathbf{x_i} + b) \geq 1 \quad \forall i = 1, \ldots, n
  $$
  где $y_i \in \{-1, +1\}$ — метки классов.

---

## Переход к Support Vector Classifier

- **Максимальный зазор** при условии $\sum_{i=1}^{p} \beta_i^2 = 1$:
  $$
  y_i(\beta_0 + \sum_{j=1}^{p} \beta_j x_{ij}) \geq M(1 - \epsilon_i)
  $$
  где $\epsilon_i \geq 0$, $\sum_{i=1}^{n} \epsilon_i \leq C$ (параметр регуляризации).

---

## Ядерные функции (Kernel Trick)

- **Ядерные функции** используются для работы в пространстве более высокой размерности без явного преобразования векторов — решают проблему нелинейной разделимости при росте размерности (dot product).

### Виды ядер:

1. **Линейное ядро:**
   $$
   K(x_i, x_j) = \sum_{k=1}^{p} x_{ik} x_{jk}
   $$

2. **Полиномиальное ядро:**
   $$
   K(x_i, x_j) = \left(1 + \sum_{k=1}^{p} x_{ik} x_{jk}\right)^d
   $$

3. **Радиально-базисное (RBF/Gaussian) ядро:**
   $$
   K(x_i, x_j) = \exp\left(-\gamma \sum_{k=1}^{p} (x_{ik} - x_{jk})^2\right)
   $$

---

## Особенности и применение

- SVM хорошо работает с высокоразмерными данными.
- Менее чувствителен к выбросам благодаря концепции опорных векторов.
- Kernel trick позволяет решать задачи нелинейной классификации.
- Требует масштабирования признаков для корректной работы.

---

> SVM — мощный и универсальный алгоритм классификации, основанный на максимизации зазора между классами и использовании опорных векторов. Ядерные функции делают SVM применимым к сложным нелинейным задачам.

# Деревья решений: терминология, построение, критерий Джини (Gini impurity)

## Ключевые понятия дерева решений

- **Splitting (разбиение)** — разделение по условию T/F.
- **Node (узел)** — любое условие проверки.
- **Root node (корневой узел)** — стартовое, самое верхнее условие.
- **Leaf node (лист, конечный узел)** — финальное, присваивает метку.
- **Parent/child nodes** — узлы-разделители и их потомки.
- **Pruning (усечение)** — удаление "слабых" веток для уменьшения переобучения.

---

## Мера Джини ("Gini impurity")

- Джини показывает, насколько "чистое" множество получилось после разбиения узла дерева. Чем ближе к 0 — тем больше большинство точек принадлежит одному классу.

### Формула Gini impurity для набора $Q$ с классами $C$:
$$
G(Q) = \sum_{c\in C} p_c(1-p_c)
$$
где $p_c$ — доля объектов класса $c$ во множестве $Q$.

Для каждого $p_c$:
$$
p_c = \frac{1}{N_Q} \sum_{x_i \in Q} 1(y_{class}=c)
$$

---

## Gini impurity для мультикатегориального признака

Если $C$ — множество всех категорий/классов ($k > 2$):
- Джини считается по всем категориям:
  $$
  G(Q) = 1 - \sum_{c \in C} (p_c)^2
  $$

**Интерпретация:**
- Если весь узел состоит из одного класса: $G(Q)=0$.
- Максимальное значение — когда классы распределены равномерно: $G(Q) \approx 1-\frac{1}{k}$.

---

## Пример (три класса, равновероятные):

Если $C = \{A, B, C\}$ и $p_A = p_B = p_C = \frac{1}{3}$:
$$
G(Q) = 1 - \left[\left(\frac{1}{3}\right)^2 + \left(\frac{1}{3}\right)^2 + \left(\frac{1}{3}\right)^2\right] \\
G(Q) = 1 - 3 \cdot \frac{1}{9} = 1 - \frac{1}{3} = \frac{2}{3} \approx 0.667
$$

---

## Общая процедура работы с Gini

- Для любого разбиения (в том числе по мульт-категориальному признаку) Gini impurity считается для каждого подузла.
- Итоговый критерий: $Weighted\ Average\ Gini = \sum \frac{|Q_{child}|}{|Q_{parent}|} G(Q_{child})$
- Лучшее разбиение — то, где (суммарная) взвешенная Gini impurity минимальна.

---

**Вывод:**  
Gini impurity одинаково применим и для бинарных, и для мульт-категориальных признаков — просто сумма считается по всем классам. В корне вся процедура минимизирует неоднородность (разнообразие) классов в каждом поддереве.

> Джини — ключевой критерий чистоты в построении деревьев решений (CART), аналог энтропии, но проще и быстрее для вычислений.

# Случайные леса (Random Forest) и их гиперпараметры

## Что такое случайный лес?

- **Случайный лес** — ансамблевый метод, состоящий из множества деревьев решений.
- Каждое дерево обучается на подвыборке данных (с возвращением) и использует случайное подмножество признаков.
- Итоговое решение принимается большинством голосов (классификация) или средним значением (регрессия).

---

## Принципы работы Random Forest

1. **Bagging на 8 наборов и создаём 8 деревьев** (каждый набор — случайная выборка с возвращением).
2. **Случайная подвыборка признаков** для каждого разбиения (обычно $\sqrt{p}$ из общего числа $p$ признаков).
3. **Мажоритарный голос** для классификации, среднее арифметическое для регрессии.

---

## Гиперпараметры случайных лесов

### Количество объектов (estimator):
- **Больше деревьев** — использование в каждом разбиении.
- Рекомендуется: от 64-128 деревьев.
- При большом количестве — стабильнее результат, но медленнее вычисления.

### Количество признаков:
- **Случайно подвыборки выдают** — использует в каждом дереве случайное подмножество.
- Стандартно применяется $\sqrt{N}$ признаков в каждом дереве при $N$ признаках в данных (для классификации).
- **Для регрессии** рекомендуется $N/3$ параметров.

### Bootstrap sample:
- Использовать ли метод построения деревьев с повторяющимися записями.
- **Bootstrapping** улучшает недообученность деревьев.
- Повторяет деревья, используя случайный набор и их объём, случайную выборку по строкам и признакам.

---

## Out-of-bag errors:

- Вычисляют OOB ошибку по объектам обучения.

### Что такое bagging?

- В случайном лесу или любом ансамблевом выбираем random данные (bootstrapped data) и финансы данные при построении на основе отдельных предсказаний деревьев (aggregated prediction).
- Используя bootstrapping, некоторые данные оставляют out-of-bag (не используем при обучении конкретного дерева).
- **OOB** — ошибка при тестировании дерева на данных, которые НЕ использовались для его обучения.
- Параметр не влияет на будущие предсказания обученной модели.
- Используется для оценки, не используются ошибки out-of-bag sample (=false по умолчанию).

---

## Преимущества Random Forest

- Снижает переобучение по сравнению с одиночными деревьями.
- Хорошо работает с большим количеством признаков и данных.
- Естественным образом оценивает важность признаков.
- Устойчив к выбросам и шуму в данных.

---

> Случайные леса — один из самых эффективных и популярных ансамблевых методов, сочетающий простоту деревьев решений с мощностью ансамблевого подхода для достижения высокого качества предсказаний.

# Бустинг: Последовательные деревья (Boosted Trees)

## Основная формула бустинга

- Результат функции — сумма простых предсказателей слабых моделей:
  $$
  F_T(x) = \sum_{t=1}^{T} f_t(x)
  $$
  где каждая $f_t(x)$ — простая модель (обычно learner).

---

## AdaBoost (адаптивный бустинг)

- **AdaBoost использует ансамбли слабых моделей**, объединённых с наилучшими весовыми суммами.
- **Принцип заключается в том**, что при построении очередной модели уделяется повышенное внимание примерам, для исправления ошибочных предсказаний предыдущих моделей.
- **Weak learner** — классификатор простой (обычно пень).
- **AdaBoost выбирает последовательность слабых моделей**, показывая лучшую результирующую модель построенного.

---

## Как строится модель в бустинге?

### Шаги алгоритма (Boosting — метод обучения):

1. **На каждую модель создаётся не сразу последовательно:**
   $$
   x_t^{(error)} = \frac{1}{n} \sum [F_{t-1}(x_i) + d_t h_t(x_i)]
   $$
   Каждая модель имеет свой вес $w_t$.

**Терминология:**
- **Точки $x_1, x_n$**
- **Предсказание без-атов $g_1, g_n, y \in \{-1,+1\}$**
- **Начальные веса $\omega_1, \ldots, \omega_n$**
- **Для модели $E(t(g),y) = e^{-y(t)}$**
- **Слабые модели $h : x \rightarrow \{-1,+1\}$**

**Алгоритм для $t$ от 1 до $T$:**

1. **Выбираем $h_t(x)$:**
   Находим слабое модели $h_t(x)$, которое минимизирует взвешенную ошибку предсказания при неправильной классификации:
   $$
   \epsilon_t = \frac{\sum \omega_{i,t}}{\sum \omega_{i,t}} 1(h_t(x_i) \neq y_i)
   $$

2. **Вычисляем $d_t = \frac{1}{2} \ln\left(\frac{1-\epsilon_t}{\epsilon_t}\right)$**

3. **Добавляем в ансамбль: $F_t(x) = F_{t-1}(x) + d_t h_t(x)$**

4. **Обновляем веса: $\omega_{i,t+1} = \omega_{i,t} e^{-y_i d_t h_t(x_i)}$**

5. **Нормализуем: $\sum \omega_{i,t+1} = 1$**

---

## Выбираем модель по принципу

- Если модель классифицированных неправильно использовании.

### Таким образом строим все деревья

**Интуитивная интерпретация:**
- Каждое такое дерево пытается сосредоточиться на тех примерах, которые предыдущие плохо классифицируют.
- Последнее построение пытается исправить ошибки модели Н комбинаций $d_t$. Первое дерево построено. ✓
- Таким образом бустинг последовательно строит всё деревья.
- Повышение интерактивности — переобучается.

---

> Бустинг — мощная техника машинного обучения, которая последовательно комбинирует слабые модели в сильную, акцентируя внимание на сложных примерах и корректируя ошибки предыдущих итераций.

# Градиентный бустинг и современные реализации

## Принцип градиентного бустинга

- В основе заложена идея **AdaBoost**, при этом используется оптимизация остатков (residual errors).
- В **градиентном бустинге** регрессия даёт глубокие деревья.
- **Коэффициент "learning rate"** используется для всех слабых моделей.
- Обучение следующей модели происходит с минимизацией остатков предыдущей модели.

---

## Пример: градиентный бустинг для регрессии

**Исходные данные:** Area (площадь), Bathrooms (ванные), Bedrooms (спальни), Price (цена)

| Area | Bath. | Bedr. | Price |   | y    | ŷ   | e   |
|------|-------|-------|--------|---|------|-----|-----|
| 200  | 3     | 2     | 500 000| → | 500  | 509 | -9  |
| 190  | 2     | 1     | 450 000| → | 450  | 509 | -59 |
| 230  | 3     | 3     | 665 000| → | 665  | 509 | 156 |

**Алгоритм:**
1. Следующее дерево старается предсказать остатки на основе работы предыдущей модели (41).
2. Затем улучшаем предсказание (F₁).

**Формулы:**
- $F_m = F_{m-1} + f_m$
- $f_m = F_{m-1} + \text{learning rate} \cdot f_m$

---

## Градиентный бустинг для классификации

- Для задач классификации для каждого класса происходит логистическая регрессия по схеме "один-против-всех" (one-vs-all logreg).

### Принцип:
$$
\hat{y} = \log\left(\frac{P}{1-P}\right), \quad P' = \frac{1}{1+e^{-\hat{y}}}
$$

---

## Интерпретация "градиентного" бустинга

- **Большая кузня во фразении обучения** — различные.
- **Learning rate** — от 0.01 до 1, влияние нового дерева → неполное полезных деревьев и возможность обучения.

---

## Реализации метода в 4 библиотеках:

1. **Scikit-Learn** (GradientBoostingClassifier)
2. **XGBoost** — быстрое ускоренное процессирование с автоматическим поблочным вычислением состояния)
3. **CatBoost** — автомат обработки категориальных переменных, используется GPU от Яндекс
4. **LightGBM** — использует GPU

---

> Градиентный бустинг — одна из наиболее эффективных техник машинного обучения, которая лежит в основе многих современных высокопроизводительных алгоритмов и широко используется в соревнованиях по Data Science.

# Наивный байес и NLP (Natural Language Processing)

## Теорема Байеса

$$
P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}
$$

где:
- $P(A|B)$ — вероятность $A$ при условии, что событие $B$ произошло
- Мы максимизируем вероятность принадлежности к классу при условии наблюдения функциональных особенностей

---

## Применение к классификации текстов

$$
X = (x_1, \ldots, x_n) \text{ — признаки}
$$
$$
C_k \text{ — принадлежность к классу}
$$

**Формула для классификации:**
$$
P(C_k|X) = \frac{P(X|C_k) \cdot P(C_k)}{P(X)}
$$

**Наиболее вероятный класс:**
$$
\hat{C} = \arg\max_{C_k} P(C_k|X)
$$

---

## Существует множество вариантов модели Наивного байеса:

- **Мультиномиальная модель**
- **Модель Гаусса** 
- **Комплементарная модель**
- **Модель Бернулли**
- **Категориальная модель**

**Мультиномиальная модель Наивного байеса** неплохо работает на векторизации слов, где мы подсчитываем смысловые то или иные слова векторного в документе (count vectorization).

---

## Пример применения

**Классификация фильмов по жанрам:**

| Фильм | top-secret | OK  | OK  | 0.25 | 0 | 1 |
|-------|------------|-----|-----|------|---|---|
| 5     | хорошо     | 0   | 2   | 5    | 1 |   |
| слово | movie      | actor | great | film |   |   |

**Вычисление вероятности:**
$P(\text{pos}) \times P(\text{movie}|\text{pos}) \times P(\text{actor}|\text{pos}) = 0.024 < P(\text{movie actor}|\text{pos})$
$0.057 < P(\text{movie actor}|\text{neg})$

Если рассмотрим наиболее вероятное "good", то тогда не заложить событие, чтобы было большое популярное слово. Но чтобы чаще был морфологический слово "good better" (параметр слишком).

---

## Извлечение признаков из текста (Feature extraction)

### Основные методы извлечения:

- **Выделение отдельных слов** (tokenизация)
- Слова, встречающиеся очень часто, можно удалить (стоп-слова), например, предлоги или вводные слова

### Term Frequency — Inverse Document Frequency (TF-IDF):

- Слово по тексту выглядит мало раз, а как них выглядящихся TF-IDF
- **Term frequency TF(t,d)** — сколько раз слово t встречается в документе d
- **Inverse document frequency** вес большинство увеличенная все слов, которые встречаются часто в корпусе документов

---

## Вычисление TF-IDF как мера общего количества семантически-богатых на множестве документов:

$$
\text{tf-idf}(t,d,D) = \text{tf}(t,d) \times \text{idf}(t,D)
$$

$$
\text{idf}(t,D) = \log \frac{N}{|\{d \in D : t \in d\}|}
$$

Чем выше TF + 0, тем чаще встречается слово.

---

> Наивный байес — простой, но эффективный алгоритм классификации текстов, основанный на теореме Байеса и предположении о независимости признаков. Широко используется в спам-фильтрах, анализе тональности и категоризации документов.

# Unsupervised Learning (обучение без учителя)

## Введение

- **Цель:** при наличии неразмеченных (unlabeled) данных найти закономерности в данных и скрытые структуры.
- **Кластеризация** — группировка объектов в кластеры по признакам.
- **Уменьшение размерности** — с помощью принципов сжимающихся в менее измерительные пространство.

---

# Кластерный k-средних (k-means Clustering)

## Принцип работы

- **Кластеризация цель** в неразмеченных данных находит похожие объекты и объединяет их в одну группу (кластер).
- **Если мы знаем кластеры, то можем буквально разделить объекты у (кластеры)** для обучения с учителем.
- Алгоритм не может количественно принимать объектов, но факт что кластеризацию применяем.

---

## Алгоритм k-means (пошагово)

1. **Шаг 1:** Выбираем количество кластеров $k$.
2. **Шаг 2:** Случайно выбираем $k$ различных точек центры кластеров.
3. **Шаг 3:** Для остальных точек берём расстояние к центрам кластеров.
4. **Шаг 4:** Вычисляем центры кластеров (среди множества точек).
5. **Шаг 5:** Останавливаем точки в том кластере чувствам центра.
6. **Шаг 6:** Повторяем шаги со тех пор, пока точки не перестанут менять цвет.

---

## Как выбрать k?

### Метод "локтя" (elbow method):
- Определяем матрицу — расстояние от центра кластера по точке — сумма квадратов расстояний (SSD — Sum of Squared Distances).

### Главное — не переоптимизировать: при k=количестве точек SSD=0.

### Ищем те значения, где увеличение k не даёт значительного уменьшения матрицы SSD.

---

## Метод силуэтов

- **Вычисляем матрицу Silhouette score:**

$$
\text{Silhouette score} = \frac{b-a}{\max(a,b)}
$$

где:
- $a$ — среднее расстояние внутри кластера
- $b$ — расстояние до ближайшего кластера

### Визуализация:
- **Среднее среди кластера**
- **Для соседнего точки**  
- **Среднее для всех кластеров**

**Диапазон значений Silhouette:**
- $-1 \leq \text{Silhouette score} \leq 1$
- $1$ — отличные кластеры
- $0$ — плохие кластеры  
- $-1$ — неправильные кластеры

---

> k-means — простой и эффективный алгоритм кластеризации, который разделяет данные на заданное количество групп, минимизируя внутрикластерную дисперсию и максимизируя различия между кластерами.

# Иерархическая кластеризация и DBSCAN

## Иерархическая кластеризация

Когда количество кластеров заранее неизвестно — поможем визуализировать кластеры.

**Алгоритм разделяет точки по возможной кластеры:**

### Дивизионный подход:
- Каждая точка принадлежит кластеру, затем кластеры объединяются.
- Каждый шаг объединяется в виде иерархической схемы.

### Агломеративный подход:
- Все точки начально в своём кластере, затем кластеры объединяют по схеме.

**В иерархической кластеризации выберём масштабные меры:**

- **Метрика близости (Similarity Metric):** по тренировкам — евклидово расстояние (близко).
- **Дендрограмма (Dendrogram):** матрица связей (Linkage Matrix) — все количества точек.

---

## DBSCAN (Density-based spatial clustering of applications with noise)

**Основная идея:** k-Means Clustering vs DBSCAN

- DBSCAN выделяет информацию по плотности интервалов по алгоритмам (оценочных и минимального количестве точек).
- В кластере основные кластеры + высокие точки.

### Параметры DBSCAN:

- **Эпсилон** — расстояние (окрестность) вокруг точки.
- **Минимальное количество точек** — мин-кол-во точек внутри эпсилон радиуса.

### Типы точек DBSCAN:

- **Core** — точка, имеющая мин-кол-во точек в эпсилон окружности (density).
- **Border** — находятся в окрестности core точек, но не имеет минимальных мин-кол-во точек окрестности.
- **Outlier** — точка, которая не держала в окружности (не имеет точек в своей окрестности).

---

## Алгоритм DBSCAN:

1. Берём случайную точку, не принадлежащую кластеру.
2. Определяем тип точки.
3. Если core — без точки окрестности попадают в кластер точки её.
4. Повторяем для всех точек без кластеров.

---

## Ключевые гиперпараметры:

- **Radius дайте epsilon** — $\varepsilon$ min_count points.

> DBSCAN превосходно справляется с кластерами произвольной формы и автоматически определяет количество кластеров, в отличие от k-means, что делает его особенно полезным для сложных пространственных данных с шумом.

# Уменьшение размерности, отбор и важность признаков

## Метод главных компонент (PCA, Principal Component Analysis)

- **Цель:** уменьшить размерность, сохранив как можно больше вариации данных.  
- **Суть:** ищем новое пространство (главные компоненты), куда проецируются исходные признаки так, что первые компоненты объясняют максимум дисперсии.
- **Последовательность действий:**
    - Вычислить ковариационную матрицу.
    - Найти собственные вектора и значения.
    - Взять $N$ наибольших собственных векторов (направление максимальной изменчивости).
    - Проецировать данные на эти вектора.

---

## Валидация и кросс-валидация для feature selection

- **K-Fold:** деление на $k$ частей, поочерёдно тестируем на каждой из них.
- **StratifiedKFold:** используется при несбалансированных классах.
- **GroupKFold:** когда есть группы, которые нельзя пересекать.
- **RepeatedKFold:** K-fold с повторами.
- Выбор зависит от структуры данных и задачи.

---

# Современные методы отбора признаков (feature selection)

## Feature importance

**Feature Importance** — любая численная мера, показывающая вклад признака в итоговое предсказание модели.  
- В деревьях решается по снижению impurity или потери.
- В линейных моделях — по значению абсолютного коэффициента.
- В ансамблях (Random Forest, Gradient Boosting) — по усреднённому приросту accuracy или уменьшению ошибки при включении/исключении признака.

---

## RFE (Recursive Feature Elimination)

- **RFE** — рекурсивное удаление/отбор признаков путём построения модели, ранжирования признаков по важности и удаления наименее значимых, пока не останется нужное число.
- Используется с опорными векторами, деревьями и линейными моделями.
- Настраивается по количеству оставляемых признаков; часто комбинируется с кросс-валидацией (RFECV).

---

## SHAP (SHapley Additive exPlanations)

- SHAP объясняет вклад каждого признака конкретного предсказания (локальная интерпретируемость модели).
- Основан на теории игр — вычисляет "цены" (Shapley values) для признаков через усреднение вклада каждого в разных комбинациях.
- Позволяет понять, как отдельные признаки повлияли на результат (в том числе для сложных моделей, в т.ч. ансамблей, бустинга, нейросетей).
- Достоинство: даёт не просто глобальную, но и локальную (для отдельных объектов) интерпретацию важности.

---

## Boruta

- Boruta — wrapper-метод на базе Random Forest:
    1. К исходному датасету добавляет искусственно перемешанные ("теневые") признаки.
    2. Строит ансамбль и сравнивает importance реальных и теневых фичей.
    3. Признаки, статистически значимо превосходящие тени, считаются важными.
- Отличен для задач с большим количеством шумовых признаков; позволяет выбрать только действительно значимые.

---

## Когда что применять

- **Feature importance из дерева или ансамбля** — базовая, быстрая оценка, пригодна для ранжирования и простой фильтрации.
- **RFE** — для поэтапного отбора и построения компактных, но информативных фичей.
- **SHAP** — для объяснимости и глубокого анализа поведения модели (особенно в продакшене).
- **Boruta** — для "вычищения" действительно важных переменных из большого набора.

---

> Грамотный отбор признаков — основа интерпретируемых, быстрых и устойчивых моделей. Используйте комбинацию методов, чтобы получить уверенные и значимые результаты.
